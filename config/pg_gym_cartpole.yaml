---

# This is an example of configuration to train Policy Gradient agent to play gym's pong game.
#
# To run this training open three terminals here and run:
# relaax-parameter-server --config ../relaax/tutorials/policy_gradient/policy_gradient.yaml
# relaax-rlx-server --config ../relaax/tutorials/policy_gradient/policy_gradient.yaml
# ../relaax/environments/OpenAI_Gym/main --rlx-server localhost:7001 --env CartPole-v0 --rnd=0 --limit 800
# honcho start -f ../relaax/tutorials/policy_gradient/pg.Procfile

relaax-parameter-server:
  --bind: localhost:7000
  --checkpoint-dir: checkpoints/pg_cartpole
  --log-level: WARNING
  --metrics-dir: metrics_pg_cartpole

relaax-rlx-server:
  --bind: 0.0.0.0:7001
  --parameter-server: localhost:7000
  --log-level: WARNING

algorithm:
  path: ../relaax/algorithms/policy_grad   # path to algorithm package

  action_size: 2                  # action size for the given environment (gym's Pong)
  state_size: [4]                 # pass flattened or n-element list for an image-like state
  preprocess: false               # if true, input == difference from previous state
  hidden_layers_size: [10]        # elements == hidden layers, each number == neurons
  batch_size: 800                 # how many steps perform before a param update
  max_global_step: 1e8            # maximum global step to stop the training when it is reached

  learning_rate: 1e-2             # learning rate which we use through whole training
  entropy_beta: 0.01              # entropy regularization constant
  rewards_gamma: 0.99             # discount factor for rewards
  rewards_norm: False             # mean centered rewards
