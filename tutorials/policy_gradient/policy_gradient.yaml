---

# This is an example of configuration to train Policy Gradient agent to play gym's pong game.
#
# To run this training open three terminals here and run:
# relaax-parameter-server --config policy_gradient.yaml
# relaax-rlx-server --config policy_gradient.yaml
# ../../environments/OpenAI_Gym/main --rlx-server localhost:7001 --env Pong-v0

relaax-parameter-server:
  --bind: localhost:7000
  --checkpoint-dir: checkpoints/pg_pong
  --log-level: WARNING
  --metrics-dir: metrics_pg_pong

relaax-rlx-server:
  --bind: 0.0.0.0:7001
  --parameter-server: localhost:7000
  --log-level: WARNING

algorithm:
  path: .                         # path to algorithm package (if we here, just . is enough)

  action_size: 1                  # action size for the given environment (Karpathy's pong)
  state_size: [6400]              # size of the input observation (flattened image 80x80 grid = 6400)
  batch_size: 10                  # how many steps perform before a param update
  max_global_step: 1e8            # maximum global step to stop the training when it is reached

  initial_learning_rate: 1e-4     # learning rate which we use through whole training
  entropy_beta: 0.01              # entropy regularization constant
  rewards_gamma: 0.99             # discount factor for rewards

  RMSProp:
    decay: 0.99                   # decay parameter for RMSProp
    epsilon: 1e-5                 # epsilon parameter for RMSProp (in a denominator sum to avoid NaN)
